# Configuration for SupervisedLearning algorithm

# Algorithm-specific settings
algorithm:
  name: "supervised_learning"
  task_type: "regression"  # "regression" or "classification"
  
# Training hyperparameters
training:
  num_epochs: 20
  batch_size: 32
  learning_rate: 1e-3
  weight_decay: 1e-5
  
  # Optimizer settings
  optimizer:
    type: "adam"  # "adam", "sgd", "rmsprop"
    betas: [0.9, 0.999]
    eps: 1e-8
  
  # Loss function settings
  loss:
    type: "auto"  # "auto", "mse", "cross_entropy", "bce"
    # For weighted losses
    class_weights: null
  
  # Learning rate scheduler
  scheduler:
    enabled: false
    type: "step"  # "step", "cosine", "exponential"
    step_size: 10
    gamma: 0.1
    
  # Early stopping
  early_stopping:
    enabled: false
    patience: 5
    min_delta: 1e-4
    monitor: "val_loss"  # "val_loss", "val_accuracy"

# Model architecture (if using built-in models)
model:
  type: "mlp"
  input_dim: 10
  hidden_dims: [64, 32]
  output_dim: 1
  dropout: 0.1
  activation: "relu"  # "relu", "gelu", "tanh", "sigmoid"

# Data settings
data:
  train_split: 0.8
  val_split: 0.2
  test_split: 0.0
  shuffle: true
  num_workers: 4
  pin_memory: true

# Logging and monitoring
logging:
  log_interval: 10  # Log every N steps
  eval_interval: 100  # Evaluate every N steps
  save_interval: 500  # Save checkpoint every N steps
  
# Validation settings
validation:
  enabled: true
  during_training: true  # Validate during training
  batch_size: 64  # Separate batch size for validation

# Checkpointing
checkpointing:
  enabled: true
  save_best_only: false
  monitor: "val_loss"
  mode: "min"  # "min" or "max"
  save_top_k: 3